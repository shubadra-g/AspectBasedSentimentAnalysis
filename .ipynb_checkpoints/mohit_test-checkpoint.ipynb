{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'hello world'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "# from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics.scorer import make_scorer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "print('success')\n",
    "'hello world'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3602, 3613)\n",
      "(3602, 3612)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'hello world'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Load data set'''\n",
    "\n",
    "df1 = pd.read_csv(\"weightxy_data2.csv\")\n",
    "# df1 = pd.read_csv(\"weightxy_data1.csv\")\n",
    "\n",
    "print(df1.shape)\n",
    "\n",
    "print(df1.iloc[:,:-1].shape)\n",
    "\n",
    "'hello world'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "3.0\n",
      "(array([  30,   81,  115,  128,  133,  138,  150,  167,  168,  244,  252,\n",
      "        280,  375,  398,  421,  455,  468,  501,  541,  542,  562,  668,\n",
      "        687,  716,  737,  797,  834,  840,  890,  916,  938,  956,  959,\n",
      "        966,  974,  991,  998, 1002, 1046, 1065, 1116, 1139, 1165, 1347,\n",
      "       1418, 1469, 1504, 1516, 1579, 1601, 1728, 1739, 1741, 1743, 1778,\n",
      "       1864, 1898, 1965, 1972, 2104, 2148, 2225, 2264, 2276, 2297, 2352,\n",
      "       2353, 2364, 2405, 2516, 2612, 2622, 2701, 2719, 2760, 2852, 2937,\n",
      "       2965, 3081, 3085, 3093, 3098, 3149, 3161, 3183, 3269, 3271, 3277,\n",
      "       3292, 3359, 3378, 3379, 3380, 3429, 3454, 3455, 3456, 3501, 3504,\n",
      "       3522, 3572, 3582, 3591], dtype=int64),)\n",
      "111\n",
      "processed df1 (3602, 3503)\n"
     ]
    }
   ],
   "source": [
    "# print(df1['Unnamed: 0'])\n",
    "\n",
    "count = 0\n",
    "# processed_df1 = df1[['class_']].copy()\n",
    "processed_df1 = pd.DataFrame()\n",
    "temp_one_AT = pd.DataFrame()\n",
    "temp_df2 = pd.DataFrame()\n",
    "\n",
    "for column in df1:\n",
    "#     print(column)\n",
    "    temp_array = np.array(df1[column].values)\n",
    "#     print(np.where(temp_array > 0)[0].shape)\n",
    "    if np.where(temp_array > 0)[0].shape[0] <= 1:\n",
    "        if pd.DataFrame.max(df1[column]) > 1:\n",
    "            temp_one_AT[column] = df1[[column]].copy()\n",
    "            count = count + 1\n",
    "            pass\n",
    "        else:\n",
    "            temp_df2[column] = df1[[column]].copy()\n",
    "            processed_df1[column] = df1[[column]].copy()\n",
    "#             count = count + 1\n",
    "#             print(column)\n",
    "    else: \n",
    "        processed_df1[column] = df1[[column]].copy()\n",
    "        pass\n",
    "\n",
    "processed_df1['temp_1'] = temp_one_AT.sum(axis=1)\n",
    "# processed_df1[temp_2] = temp_df2.sum(axis=1)\n",
    "    \n",
    "print(count)\n",
    "print('processed df1', processed_df1.shape)\n",
    "#     if pd.DataFrame.max(df1[column]) == 0:\n",
    "#         print(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success\n",
      "(3602, 3502)\n",
      "(3602,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'hello world'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_train, Y_train = df1.iloc[:,:-1], df1['class_']\n",
    "X_train, Y_train = df1.drop(['class_'], axis = 1), df1['class_']\n",
    "# X_train, Y_train = processed_df1.drop(['class_'], axis = 1), processed_df1['class_']\n",
    "\n",
    "# svm_clf = svm.SVC()\n",
    "svm_clf = svm.LinearSVC(C = 0.1, loss='squared_hinge', penalty = 'l2')\n",
    "\n",
    "print('success')\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "\n",
    "'hello world'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': array([ 0.20857048,  0.26564789,  0.29708409,  0.23439932,  0.24126244,\n",
      "        0.26695776,  0.24413681,  0.25002694,  0.44679451,  0.23443484]), 'score_time': array([ 0.04688525,  0.0156281 ,  0.        ,  0.        ,  0.01560831,\n",
      "        0.01432419,  0.01561904,  0.        ,  0.01596546,  0.01561809]), 'test_precision_micro': array([ 0.71823204,  0.7320442 ,  0.7320442 ,  0.66759003,  0.725     ,\n",
      "        0.70752089,  0.70473538,  0.67688022,  0.70752089,  0.67409471]), 'train_precision_micro': array([ 0.9037037 ,  0.90524691,  0.90246914,  0.91052144,  0.90438001,\n",
      "        0.9044095 ,  0.90502621,  0.90810977,  0.90410114,  0.90502621]), 'test_recall_micro': array([ 0.71823204,  0.7320442 ,  0.7320442 ,  0.66759003,  0.725     ,\n",
      "        0.70752089,  0.70473538,  0.67688022,  0.70752089,  0.67409471]), 'train_recall_micro': array([ 0.9037037 ,  0.90524691,  0.90246914,  0.91052144,  0.90438001,\n",
      "        0.9044095 ,  0.90502621,  0.90810977,  0.90410114,  0.90502621]), 'test_accuracy': array([ 0.71823204,  0.7320442 ,  0.7320442 ,  0.66759003,  0.725     ,\n",
      "        0.70752089,  0.70473538,  0.67688022,  0.70752089,  0.67409471]), 'train_accuracy': array([ 0.9037037 ,  0.90524691,  0.90246914,  0.91052144,  0.90438001,\n",
      "        0.9044095 ,  0.90502621,  0.90810977,  0.90410114,  0.90502621])}\n",
      "success\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'hello world'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Cross validation'''\n",
    "scores = cross_validate(svm_clf, X_train, Y_train, cv = 10, scoring = ['precision_micro', 'recall_micro', 'accuracy'] )\n",
    "\n",
    "print(scores)\n",
    "print('success')\n",
    "'hello world'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1 -1  1 ...,  1  0  0]\n",
      "success\n",
      "\n",
      "\n",
      "Model Accuracy is: 70.4609%\n",
      "Pr, Re scores wrt each class\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.49      0.60      0.54       651\n",
      "          1       0.32      0.52      0.39       388\n",
      "         -1       0.90      0.76      0.82      2563\n",
      "\n",
      "avg / total       0.76      0.70      0.73      3602\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''Cross validation'''\n",
    "y_pred = cross_val_predict(svm_clf, X_train, Y_train, cv = 10) #, scoring = 'accuracy')\n",
    "\n",
    "print(y_pred)\n",
    "print('success')\n",
    "'hello world'\n",
    "\n",
    "\n",
    "mod_accracy = accuracy_score(y_pred, Y_train)\n",
    "print('\\n\\nModel Accuracy is: {:.4%}' .format(mod_accracy))\n",
    "\n",
    "target_names = ['0', '1', '-1']\n",
    "print('Pr, Re scores wrt each class')\n",
    "print(classification_report(y_pred, Y_train, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "something = cross_val_score(svm_clf, X_train, Y_train, cv = 10 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.70258621  0.69396552  0.71982759  0.70689655  0.73706897  0.6969697\n",
      "  0.70434783  0.73043478  0.74782609  0.75217391]\n"
     ]
    }
   ],
   "source": [
    "print(something)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(len(something))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
