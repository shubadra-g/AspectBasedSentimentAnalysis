{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'hello world'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "# from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_validate, cross_val_predict\n",
    "from sklearn.metrics.scorer import make_scorer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "print('success')\n",
    "'hello world'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2313, 2969)\n",
      "(2313, 2968)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'hello world'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Load data set'''\n",
    "df1 = pd.read_csv(\"weightxy_data1.csv\")\n",
    "print(df1.shape)\n",
    "print(df1.iloc[:,:-1].shape)\n",
    "'hello world'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success\n",
      "(2313, 2968)\n",
      "(2313,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'hello world'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_train, X_test, Y_train, Y_test = train_test_split(df1.iloc[:,:-1], df1['class_'], test_size = 0.3, random_state =42)\n",
    "X_train, Y_train = df1.iloc[:,:-1], df1['class_']\n",
    "# svm_clf = svm.SVC(kernel = 'linear')\n",
    "svm_clf = svm.LinearSVC()\n",
    "print('success')\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "'hello world'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['fit_time', 'score_time', 'test_score', 'train_score'])\n",
      "success\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'hello world'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Cross validation'''\n",
    "scores = cross_validate(svm_clf, X_train, Y_train, cv = 10, scoring = 'accuracy' )\n",
    "\n",
    "print(scores.keys())\n",
    "print('success')\n",
    "'hello world'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': array([ 0.22197294,  0.20849609,  0.21877027,  0.21876812,  0.2257154 ,\n",
      "        0.21877003,  0.20975637,  0.21826267,  0.21795893,  0.18752074]), 'score_time': array([ 0.        ,  0.        ,  0.01562881,  0.        ,  0.01562834,\n",
      "        0.        ,  0.        ,  0.01563001,  0.        ,  0.        ]), 'test_score': array([ 0.68965517,  0.69827586,  0.73706897,  0.70258621,  0.68534483,\n",
      "        0.7112069 ,  0.72727273,  0.72608696,  0.74347826,  0.74347826]), 'train_score': array([ 0.98606439,  0.98558385,  0.98558385,  0.98462278,  0.98510332,\n",
      "        0.98750601,  0.98847262,  0.98415747,  0.98511762,  0.98463754])}\n"
     ]
    }
   ],
   "source": [
    "print(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''not needed anymore'''\n",
    "# print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "'''Train the svm clf'''\n",
    "# svm_clf.fit(X_train, Y_train)\n",
    "# print('trained the svm')\n",
    "# 'hello world'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'hello world'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''not needed anymore'''\n",
    "# t_pred = svm_clf.predict(X_test)\n",
    "# mod_accracy = accuracy_score(Y_test, t_pred)\n",
    "# print('success')\n",
    "# 'hello world'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Scores for SVM: ***\n",
      "Pr, Re scores wrt each class\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.80      0.76       264\n",
      "          1       0.54      0.37      0.44       131\n",
      "         -1       0.79      0.82      0.80       299\n",
      "\n",
      "avg / total       0.72      0.73      0.72       694\n",
      "\n",
      "\n",
      "\n",
      "Model Accuracy is: 72.7666%\n",
      "\n",
      "\n",
      "Precision Score is: 71.5677%\n",
      "\n",
      "\n",
      "Recall Score is: 72.7666%\n",
      "\n",
      "\n",
      "F1-Score is: 71.7553%\n"
     ]
    }
   ],
   "source": [
    "'''calculate the precision recall and stuff'''\n",
    "\n",
    "t_precision = precision_score(Y_test, t_pred, average='weighted')\n",
    "t_recall = recall_score(Y_test, t_pred, average='weighted')\n",
    "t_f1_score = f1_score(Y_test, t_pred, average='weighted')\n",
    "\n",
    "print('*** Scores for SVM: ***')\n",
    "target_names = ['0', '1', '-1']\n",
    "print('Pr, Re scores wrt each class')\n",
    "print(classification_report(Y_test, t_pred, target_names=target_names))\n",
    "\n",
    "print('\\n\\nModel Accuracy is: {:.4%}' .format(mod_accracy))\n",
    "print('\\n\\nPrecision Score is: {:.4%}' .format(t_precision))\n",
    "print('\\n\\nRecall Score is: {:.4%}' .format(t_recall))\n",
    "print('\\n\\nF1-Score is: {:.4%}' .format(t_f1_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
